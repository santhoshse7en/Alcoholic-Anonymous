{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alcholic Anonymous News articles extraction from Daily Sun. Data Extraction of following parameters\n",
    "- Headline\n",
    "- Description\n",
    "- Author\n",
    "- Published_Date\n",
    "- News\n",
    "- URL\n",
    "- Keywords\n",
    "- Summary\n",
    "\n",
    "### Importing the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options # enables options in web browser\n",
    "from selenium import webdriver # web-based automation tool for Python\n",
    "from newspaper import Article # Article scraping & curation\n",
    "from bs4 import BeautifulSoup # Python library for pulling data out of HTML and XML files\n",
    "from requests import get # standard for making HTTP requests in Python\n",
    "import pandas as pd # library written for data manipulation and analysis\n",
    "import sys, time #  System-specific parameters and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Empty lists for Alcholic Anonymous News Articles parameters data to be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines, descriptions, dates, authors, news, keywords, summaries, urls = [], [], [], [], [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the total no.of.pages by total no.of articles from google search results¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'Alcoholics Anonymous site:www.dailysun.co.za'\n",
    "\n",
    "url = 'https://www.google.com/search?q=' + '+'.join(keyword.split())\n",
    "\n",
    "soup = BeautifulSoup(get(url).text, 'lxml')\n",
    "try:\n",
    "    # Extracts the digits if it the resulted number without comma ','. eg: About 680 results (0.23 seconds)\n",
    "    max_pages = round([int(s) for s in soup.select_one('div#resultStats').text.split() if s.isdigit()][0]/10)\n",
    "    max_pages = max_pages + 1\n",
    "except:\n",
    "    # Extracts the digits if it the resulted number without comma ','. eg: About 1,080 results (0.23 seconds)\n",
    "    max_pages = round(int(''.join(i for i in soup.select_one('div#resultStats').text if i.isdigit()))/10)\n",
    "    max_pages = max_pages + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterates max_pages value through while loop. Scraping the Articles urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1 : 3\r"
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "options.headless = True\n",
    "browser = webdriver.Chrome(options=options)\n",
    "browser.get(url)\n",
    "\n",
    "index = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        index +=1\n",
    "        page = browser.page_source\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "        linky = [soup.select('.r')[i].a['href'] for i in range(len(soup.select('.r')))]\n",
    "        urls.extend(linky)\n",
    "        if index == max_pages:\n",
    "            break\n",
    "        browser.find_element_by_xpath('//*[@id=\"pnnext\"]/span[2]').click()\n",
    "        time.sleep(2)\n",
    "        sys.stdout.write('\\r' + str(index) + ' : ' + str(max_pages) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To remove duplicates urls entries in the list by executing below line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "urls = list(dict.fromkeys(urls))\n",
    "print(len(urls), type(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterates urls through for loop. Scraping the Articles with above parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54.5 sdailysun.co.za/Search/Lost?p=12s-bust-booze-thieves-20160225eck-20181002ile=truerue\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, url in enumerate(urls):\n",
    "    try:\n",
    "        # Parse the url to NewsPlease \n",
    "        soup = BeautifulSoup(get(url).text, 'lxml')\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        article.nlp()\n",
    "        \n",
    "        # Extracts the Headlines\n",
    "        try:\n",
    "            try:\n",
    "                headlines.append(soup.select_one('meta[property=\"og:title\"]')['content'].strip())\n",
    "            except:\n",
    "                headlines.append(article.title.strip())\n",
    "        except:\n",
    "            headlines.append(None)\n",
    "            \n",
    "        # Extracts the Descriptions    \n",
    "        try:\n",
    "            try:\n",
    "                descriptions.append(soup.select_one('meta[name=\"description\"]')['content'].strip().replace('\\n', ' '))\n",
    "            except:\n",
    "                descriptions.append(article.meta_description.strip())\n",
    "        except:\n",
    "            descriptions.append(None)\n",
    "            \n",
    "        # Extracts the Authors\n",
    "        try:\n",
    "            try:\n",
    "                authors.append(soup.select_one('meta[name=\"cXenseParse:tss-byline\"]')['content'].strip())\n",
    "            except:\n",
    "                authors.append(article.authors.strip())\n",
    "        except:\n",
    "            authors.append(None)\n",
    "        \n",
    "        # Extracts the published dates\n",
    "        try:\n",
    "            try:\n",
    "                dates.append(soup.select_one('meta[name=\"cXenseParse:recs:publishtime\"]')['content'].strip())\n",
    "            except:\n",
    "                dates.append(str(article.publish_date))\n",
    "        except:\n",
    "            dates.append(None)\n",
    "            \n",
    "        # Extracts the news articles\n",
    "        try:\n",
    "            try:\n",
    "                news.append(soup.select_one('div.content').text.replace('\\n', '').strip())\n",
    "            except:\n",
    "                news.append(article.text.strip())\n",
    "        except:\n",
    "            news.append(None)\n",
    "            \n",
    "        # Extracts Keywords and Summaries    \n",
    "        try:\n",
    "            keywords.append(article.keywords)\n",
    "            summaries.append(article.summary)\n",
    "        except:\n",
    "            keywords.append(None)\n",
    "            summaries.append(None)\n",
    "            \n",
    "    except:\n",
    "        headlines.append(None)\n",
    "        descriptions.append(None)\n",
    "        authors.append(None)\n",
    "        dates.append(None)\n",
    "        news.append(None)\n",
    "        keywords.append(None)\n",
    "        summaries.append(None)\n",
    "\n",
    "    sys.stdout.write('\\r' + str(index) + ' : ' + str(url) + '\\r')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Array Length of each list to create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 11 11 11 11 11 11 11\n"
     ]
    }
   ],
   "source": [
    "print(len(headlines), len(descriptions), len(authors), len(dates), len(news), len(keywords), len(summaries), len(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a csv file after checking array length and droping the missing values from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published_Dates</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOOZE RUINS LIVES!</td>\n",
       "      <td>“THE wake-up call for me should have been the ...</td>\n",
       "      <td>Jabu Kumalo</td>\n",
       "      <td>2018-08-15T14:30:02.000Z</td>\n",
       "      <td>“THE wake-up call for me should have been the ...</td>\n",
       "      <td>[drinking, hit, hat, imbizo, involved, decided...</td>\n",
       "      <td>He told Daily Sun he sometimes couldn’t believ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALCOHOLICS, IT'S NEVER TOO LATE!</td>\n",
       "      <td>IF YOU have a drinking problem or you know som...</td>\n",
       "      <td>Jabu Kumalo</td>\n",
       "      <td>2017-10-11T15:30:03.000Z</td>\n",
       "      <td>IF YOU have a drinking problem or you know som...</td>\n",
       "      <td>[problem, drinking, soweto, group, west, late,...</td>\n",
       "      <td>IF YOU have a drinking problem or you know som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my girlfriend drinks too much</td>\n",
       "      <td>WORRIED LOVER writes: My girlfriend drinks too...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WORRIED LOVER writes:My girlfriend drinks too ...</td>\n",
       "      <td>[kick, im, drinks, fear, love, writesmy, try, ...</td>\n",
       "      <td>WORRIED LOVER writes:My girlfriend drinks too ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NO BOOZE FOR THESE TWO!</td>\n",
       "      <td>SUNDAY was a joyful day as a husband and wife ...</td>\n",
       "      <td>Jabu Kumalo</td>\n",
       "      <td>2018-10-03T18:00:10.000Z</td>\n",
       "      <td>SUNDAY was a joyful day as a husband and wife ...</td>\n",
       "      <td>[times, soweto, yearsshe, yearsthe, imbizo, wi...</td>\n",
       "      <td>SUNDAY was a joyful day as a husband and wife ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BABY MAMA LIKES BOOZE</td>\n",
       "      <td>Dear MizzB.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Dear MizzBI’m a 24-year-old man and I have a p...</td>\n",
       "      <td>[drink, times, way, stop, baby, think, things,...</td>\n",
       "      <td>I don’t even drink and I’ve spoken to her many...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Headlines  \\\n",
       "0                BOOZE RUINS LIVES!   \n",
       "1  ALCOHOLICS, IT'S NEVER TOO LATE!   \n",
       "2     my girlfriend drinks too much   \n",
       "3           NO BOOZE FOR THESE TWO!   \n",
       "4             BABY MAMA LIKES BOOZE   \n",
       "\n",
       "                                        Descriptions      Authors  \\\n",
       "0  “THE wake-up call for me should have been the ...  Jabu Kumalo   \n",
       "1  IF YOU have a drinking problem or you know som...  Jabu Kumalo   \n",
       "2  WORRIED LOVER writes: My girlfriend drinks too...         None   \n",
       "3  SUNDAY was a joyful day as a husband and wife ...  Jabu Kumalo   \n",
       "4                                        Dear MizzB.         None   \n",
       "\n",
       "            Published_Dates  \\\n",
       "0  2018-08-15T14:30:02.000Z   \n",
       "1  2017-10-11T15:30:03.000Z   \n",
       "2                      None   \n",
       "3  2018-10-03T18:00:10.000Z   \n",
       "4                      None   \n",
       "\n",
       "                                            Articles  \\\n",
       "0  “THE wake-up call for me should have been the ...   \n",
       "1  IF YOU have a drinking problem or you know som...   \n",
       "2  WORRIED LOVER writes:My girlfriend drinks too ...   \n",
       "3  SUNDAY was a joyful day as a husband and wife ...   \n",
       "4  Dear MizzBI’m a 24-year-old man and I have a p...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  [drinking, hit, hat, imbizo, involved, decided...   \n",
       "1  [problem, drinking, soweto, group, west, late,...   \n",
       "2  [kick, im, drinks, fear, love, writesmy, try, ...   \n",
       "3  [times, soweto, yearsshe, yearsthe, imbizo, wi...   \n",
       "4  [drink, times, way, stop, baby, think, things,...   \n",
       "\n",
       "                                           Summaries  \n",
       "0  He told Daily Sun he sometimes couldn’t believ...  \n",
       "1  IF YOU have a drinking problem or you know som...  \n",
       "2  WORRIED LOVER writes:My girlfriend drinks too ...  \n",
       "3  SUNDAY was a joyful day as a husband and wife ...  \n",
       "4  I don’t even drink and I’ve spoken to her many...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl = pd.DataFrame({'Headlines' : headlines,\n",
    "                    'Descriptions' : descriptions,\n",
    "                    'Authors' : authors,\n",
    "                    'Published_Dates' : dates, \n",
    "                    'Articles' : news,\n",
    "                    'Keywords' : keywords,\n",
    "                    'Summaries' : summaries,})\n",
    "#tbl = tbl.dropna()\n",
    "tbl.to_csv('Daily_Sun.csv', index=False)\n",
    "tbl.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
