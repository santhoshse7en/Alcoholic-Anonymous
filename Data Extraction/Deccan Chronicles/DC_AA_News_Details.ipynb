{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options # Options in web browser\n",
    "from selenium import webdriver # web-based automation tool for Python\n",
    "from newsplease import NewsPlease # An integrated web crawler and information extractor for news \n",
    "from bs4 import BeautifulSoup # Python library for pulling data out of HTML and XML files\n",
    "from requests import get # standard for making HTTP requests in Python\n",
    "import pandas as pd # library written for data manipulation and analysis\n",
    "import sys #  System-specific parameters and functions\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url= 'https://www.deccanchronicle.com/google-search?q=Alcoholic%20Anonymous'\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options=options\n",
    "browser = webdriver.Chrome(options=options)\n",
    "browser.maximize_window()\n",
    "browser.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = browser.page_source\n",
    "soup = BeautifulSoup(res, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = [soup.select('.gsc-cursor-page')[i].text.strip() for i in range(len(soup.select('.gsc-cursor-page')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "urls = []\n",
    "try:\n",
    "    # Iterating the same loop twice. Because It's throws an error it can't reach the google search page numbers and on second time its run smoothly\n",
    "    for page in pages:\n",
    "        time.sleep(1)\n",
    "        page = browser.find_element_by_xpath('//*[@id=\"___gcse_1\"]/div/div/div/div[5]/div[2]/div[1]/div/div[2]/div[11]/div/div['+page+']').click()\n",
    "        time.sleep(1)\n",
    "        res = browser.page_source\n",
    "        soup = BeautifulSoup(res, 'lxml')\n",
    "        for i in range(len(soup.select('.gsc-webResult'))):\n",
    "            urls.append(soup.select('.gsc-webResult')[i].a['href'])\n",
    "        time.sleep(.5)\n",
    "except:\n",
    "    for page in pages:\n",
    "        time.sleep(1)\n",
    "        page = browser.find_element_by_xpath('//*[@id=\"___gcse_1\"]/div/div/div/div[5]/div[2]/div[1]/div/div[2]/div[11]/div/div['+page+']').click()\n",
    "        time.sleep(1)\n",
    "        res = browser.page_source\n",
    "        soup = BeautifulSoup(res, 'lxml')\n",
    "        for i in range(len(soup.select('.gsc-webResult'))):\n",
    "            urls.append(soup.select('.gsc-webResult')[i].a['href'])\n",
    "        time.sleep(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In google search search results it store cache url which was in the same tag. To remove duplicates execute below line\n",
    "urls = list(dict.fromkeys(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline, time, news, image, authors = [], [], [], [], []\n",
    "\n",
    "for index, url in enumerate(urls):\n",
    "    # Parse the url to NewsPlease\n",
    "    article = NewsPlease.from_url(url)\n",
    "    \n",
    "    try:        \n",
    "        # Extracts the Headlines of News Article related to AA\n",
    "        headline.append(article.title.strip())\n",
    "    except:\n",
    "        headline.append(None)\n",
    "    \n",
    "    try:        \n",
    "        # Extracts the Authors of News Article related to AA\n",
    "        authors.append(article.authors)\n",
    "    except:\n",
    "        authors.append(None)\n",
    "    \n",
    "    try:    \n",
    "        # Extracts the Main_Image_url of News Article related to AA\n",
    "        image.append(article.image_url)\n",
    "    except:\n",
    "        image.append(None)\n",
    "    \n",
    "    try:\n",
    "        # Extracts the Published_Date of News Article related to AA\n",
    "        time.append(str(article.date_publish))\n",
    "    except:\n",
    "        time.append(None)\n",
    "        \n",
    "    try:\n",
    "        # Extracts the Main_News from Article related to AA\n",
    "        news.append(article.text.replace('\\n', '').replace('\\r', '').strip())\n",
    "    except:\n",
    "        news.append(None)\n",
    "\n",
    "    sys.stdout.write('\\r' + str(index) + ' : ' + str(url) + '\\r')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Array Length\n",
    "print(len(headline), len(authors), len(image), len(time), len(news), len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = pd.DataFrame({'Headline' : headline,\n",
    "                    'Authors' : authors,\n",
    "                    'Main_Image' : image,\n",
    "                    'Published_Date' : time,\n",
    "                    'News' : news,\n",
    "                    'Source_urls' : urls})\n",
    "tbl.to_csv('Deccan_Chronicles_AA_News_DETAILS.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'urls' : urls})\n",
    "df.to_csv('DC_urls.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
