# Import Python Packages
from selenium.webdriver.support import expected_conditions as ec
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.common.by import By
from newsplease import NewsPlease
from selenium import webdriver
import pandas as pd 
import sys, time

# Running Chrome Headless
options = Options()
options.headless = True
driver = webdriver.Chrome(options=options)
driver.get('https://www.bbc.co.uk/search?q=ALCOHOLICS+ANONYMOUS&filter=news')
wait = WebDriverWait(driver, 10)

index, maxclicks = 0, 26
t, dtp, iu, a, td, url = [], [], [], [], [], []

# Click event generated by Selenium

while index<maxclicks:
	try:
		index += 1
		owl = wait.until(ec.visibility_of_element_located((By.CLASS_NAME, "more"))).click()
		sys.stdout.write('\r' + str(index) + ' - ' + 'clicks has made out of' + ' - ' + str(maxclicks) + '\r')
		sys.stdout.flush()
	except TimeoutException:
		break

# Scraping the Alcoholic Anonymous news link from BBC
review_elems = driver.find_elements_by_class_name('rs_touch')
for news in review_elems:
    url.append(news.get_attribute('href'))
sys.stdout.write('\r' + '\n Done!' + '\r')
sys.stdout.flush()
driver.quit()

# Scraping the Alcoholic Anonymous related news details from BBC
for index, link in enumerate(url):
    try:
        article = NewsPlease.from_url(link)
        t.append(article.title)
        dtp.append(str(article.date_publish))
        iu.append(article.image_url)
        td.append(article.text)
        a.append(article.authors)
    except:
        t.append(None)
        dtp.append(None)
        iu.append(None)
        a.append(None)
        td.append(None)

    sys.stdout.write('\r' + str(index) + ' : ' + str(link) + '\r')
    sys.stdout.flush()

# Creating Dataframe from extracted data
tbl = pd.DataFrame({'title' : t, 'Author' : a, 'Date' : dtp, 'Image_url' : iu, 'News' : td})
tbl.to_excel('BBC_AA_News.xlsx', engine='xlsxwriter')