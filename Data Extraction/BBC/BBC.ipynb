{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alcholic Anonymous News articles extraction from BBC. Data Extraction of following parameters\n",
    "- Headline\n",
    "- Description\n",
    "- Author\n",
    "- Published_Date\n",
    "- News\n",
    "- URL\n",
    "- Keywords\n",
    "- Summary\n",
    "\n",
    "### Importing the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options # enables options in web browser\n",
    "from selenium import webdriver # web-based automation tool for Python\n",
    "from newspaper import Article # Article scraping & curation\n",
    "from bs4 import BeautifulSoup # Python library for pulling data out of HTML and XML files\n",
    "from requests import get # standard for making HTTP requests in Python\n",
    "import pandas as pd # library written for data manipulation and analysis\n",
    "import sys, time #  System-specific parameters and functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists for Alcholic Anonymous News Articles extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines, descriptions, dates, authors, news, keywords, summaries, urls = [], [], [], [], [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the total no.of.pages by total no.of articles from google search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'Alcoholics Anonymous site:www.bbc.co.uk'\n",
    "\n",
    "url = 'https://www.google.com/search?q=' + '+'.join(keyword.split())\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "browser = webdriver.Chrome(options=options)\n",
    "browser.get(url)\n",
    "\n",
    "page = browser.page_source\n",
    "soup = BeautifulSoup(page, 'lxml')\n",
    "max_pages = round([int(s) for s in soup.select_one('#resultStats').text.split() if s.isdigit()][0]/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterates max_pages value through while loop. Scraping the Articles urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 : 89\r"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        index +=1\n",
    "        page = browser.page_source\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "        linky = [soup.select('.r')[i].a['href'] for i in range(len(soup.select('.r')))]\n",
    "        urls.extend(linky)\n",
    "        if index == max_pages:\n",
    "            break\n",
    "        browser.find_element_by_xpath('//*[@id=\"pnnext\"]/span[2]').click()\n",
    "        time.sleep(2)\n",
    "        sys.stdout.write('\\r' + str(index) + ' : ' + str(max_pages) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the total no.of.pages by total no.of articles from google search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'Alcoholics Anonymous site:www.bbc.com'\n",
    "\n",
    "url = 'https://www.google.com/search?q=' + '+'.join(keyword.split())\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "browser = webdriver.Chrome(options=options)\n",
    "browser.get(url)\n",
    "\n",
    "page = browser.page_source\n",
    "soup = BeautifulSoup(page, 'lxml')\n",
    "max_pages = round([int(s) for s in soup.select_one('#resultStats').text.split() if s.isdigit()][0]/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterates max_pages value through while loop. Scraping the Articles urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 : 30\r"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        index +=1\n",
    "        page = browser.page_source\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "        linky = [soup.select('.r')[i].a['href'] for i in range(len(soup.select('.r')))]\n",
    "        urls.extend(linky)\n",
    "        if index == max_pages:\n",
    "            break\n",
    "        browser.find_element_by_xpath('//*[@id=\"pnnext\"]/span[2]').click()\n",
    "        time.sleep(2)\n",
    "        sys.stdout.write('\\r' + str(index) + ' : ' + str(max_pages) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To remove duplicates urls entries in the list by executing below line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "urls = list(dict.fromkeys(urls))\n",
    "print(len(urls), type(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterates urls through for loop. Scraping the Articles with above parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385 : https://www.bbc.com/news/uk-england-tees-1950708651ty-what-makes-these-three-young-people-worryashedctsince-1999tynd-children\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\ProgramData\\Anaconda3\\lib\\site-packages\\jieba\\dict.txt ...\n",
      "Dumping model to file cache C:\\Users\\GM\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 4.021788120269775 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33min 41sc.com/news/live/uk-england-beds-bucks-herts-3289775725.stm-tell-if-youre-a-workaholic\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, url in enumerate(urls):\n",
    "    try:\n",
    "        # Parse the url to NewsPlease \n",
    "        soup = BeautifulSoup(get(url).text, 'lxml')\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        article.nlp()\n",
    "        \n",
    "        # Extracts the Headlines\n",
    "        try:\n",
    "            try:\n",
    "                headlines.append(article.title.strip())\n",
    "            except:\n",
    "                headlines.append(soup.select_one('meta[property=\"og:title\"]')['content'].strip())\n",
    "        except:\n",
    "            headlines.append(None)\n",
    "            \n",
    "        # Extracts the Descriptions    \n",
    "        try:\n",
    "            try:\n",
    "                descriptions.append(soup.select_one('meta[property=\"og:description\"]')['content'].strip().replace('\\n', ' '))\n",
    "            except:\n",
    "                descriptions.append(article.meta_description.strip())\n",
    "        except:\n",
    "            descriptions.append(None)\n",
    "            \n",
    "        # Extracts the Authors\n",
    "        try:\n",
    "            try:\n",
    "                authors.append(soup.select_one('meta[name=\"author\"]')['content'].strip())\n",
    "            except:\n",
    "                authors.append(article.authors.strip())\n",
    "        except:\n",
    "            authors.append(None)\n",
    "        \n",
    "        # Extracts the published dates\n",
    "        try:\n",
    "            try:\n",
    "                dates.append(soup.select_one('meta[property=\"article:published_time\"]')['content'].strip())\n",
    "            except:\n",
    "                dates.append(str(article.publish_date))\n",
    "        except:\n",
    "            dates.append(None)\n",
    "            \n",
    "        # Extracts the news articles\n",
    "        try:\n",
    "            try:\n",
    "                news.append(soup.select_one('.storyText').text.replace('\\n', '').strip())\n",
    "            except:\n",
    "                news.append(article.text.strip())\n",
    "        except:\n",
    "            news.append(None)\n",
    "            \n",
    "        # Extracts Keywords and Summaries    \n",
    "        try:\n",
    "            keywords.append(article.keywords)\n",
    "            summaries.append(article.summary)\n",
    "        except:\n",
    "            keywords.append(None)\n",
    "            summaries.append(None)\n",
    "            \n",
    "    except:\n",
    "        headlines.append(None)\n",
    "        descriptions.append(None)\n",
    "        authors.append(None)\n",
    "        dates.append(None)\n",
    "        news.append(None)\n",
    "        keywords.append(None)\n",
    "        summaries.append(None)\n",
    "\n",
    "    sys.stdout.write('\\r' + str(index) + ' : ' + str(url) + '\\r')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Array Length of each list to create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 401 401 401 401 401 401 401\n"
     ]
    }
   ],
   "source": [
    "print(len(headlines), len(descriptions), len(authors), len(dates), len(news), len(keywords), len(summaries), len(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a csv file after checking array length and droping the missing values from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published_Dates</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Summaries</th>\n",
       "      <th>Source_URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every university 'needs' Alcoholics Anonymous ...</td>\n",
       "      <td>Alcoholics Anonymous says the number of younge...</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-07-31T16:54:32+00:00</td>\n",
       "      <td>Image copyright Getty Images\\n\\nAlcoholics Ano...</td>\n",
       "      <td>[aa, meetings, student, wasnt, really, preside...</td>\n",
       "      <td>Image copyright Getty ImagesAlcoholics Anonymo...</td>\n",
       "      <td>https://www.bbc.co.uk/news/amp/uk-wales-45023075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What happens in an Alcoholics Anonymous meeting?</td>\n",
       "      <td>Members of Alcoholics Anonymous are marking it...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Image caption The true nature of alcoholism is...</td>\n",
       "      <td>[aa, drink, woman, bad, life, god, meeting, dr...</td>\n",
       "      <td>Image caption The true nature of alcoholism is...</td>\n",
       "      <td>https://www.bbc.co.uk/news/10280806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The many groups that have copied Alcoholics An...</td>\n",
       "      <td>Alcoholics Anonymous was founded 80 years ago....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Image copyright Other Image caption An AA meet...</td>\n",
       "      <td>[aa, meeting, 12, addiction, groups, 12step, a...</td>\n",
       "      <td>But Peter hasn't tasted alcohol in 34 years, a...</td>\n",
       "      <td>https://www.bbc.co.uk/news/magazine-33049093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alcoholics Anonymous</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>[alcoholics, anonymous]</td>\n",
       "      <td></td>\n",
       "      <td>https://www.bbc.co.uk/programmes/topics/Alcoho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sir Anthony Hopkins opens up on alcohol battle</td>\n",
       "      <td>The Oscar-winning star says he was \"disgusted,...</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-07-27T09:28:17+00:00</td>\n",
       "      <td>Image copyright Greg Doherty / Getty Images Im...</td>\n",
       "      <td>[image, sir, alcohol, early, woman, battle, ho...</td>\n",
       "      <td>Image copyright Greg Doherty / Getty Images Im...</td>\n",
       "      <td>https://www.bbc.co.uk/news/amp/uk-wales-south-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Headlines  \\\n",
       "0  Every university 'needs' Alcoholics Anonymous ...   \n",
       "1   What happens in an Alcoholics Anonymous meeting?   \n",
       "2  The many groups that have copied Alcoholics An...   \n",
       "3                               Alcoholics Anonymous   \n",
       "4     Sir Anthony Hopkins opens up on alcohol battle   \n",
       "\n",
       "                                        Descriptions Authors  \\\n",
       "0  Alcoholics Anonymous says the number of younge...    None   \n",
       "1  Members of Alcoholics Anonymous are marking it...    None   \n",
       "2  Alcoholics Anonymous was founded 80 years ago....    None   \n",
       "3                                                       None   \n",
       "4  The Oscar-winning star says he was \"disgusted,...    None   \n",
       "\n",
       "             Published_Dates  \\\n",
       "0  2018-07-31T16:54:32+00:00   \n",
       "1                       None   \n",
       "2                       None   \n",
       "3                       None   \n",
       "4  2018-07-27T09:28:17+00:00   \n",
       "\n",
       "                                            Articles  \\\n",
       "0  Image copyright Getty Images\\n\\nAlcoholics Ano...   \n",
       "1  Image caption The true nature of alcoholism is...   \n",
       "2  Image copyright Other Image caption An AA meet...   \n",
       "3                                                      \n",
       "4  Image copyright Greg Doherty / Getty Images Im...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  [aa, meetings, student, wasnt, really, preside...   \n",
       "1  [aa, drink, woman, bad, life, god, meeting, dr...   \n",
       "2  [aa, meeting, 12, addiction, groups, 12step, a...   \n",
       "3                            [alcoholics, anonymous]   \n",
       "4  [image, sir, alcohol, early, woman, battle, ho...   \n",
       "\n",
       "                                           Summaries  \\\n",
       "0  Image copyright Getty ImagesAlcoholics Anonymo...   \n",
       "1  Image caption The true nature of alcoholism is...   \n",
       "2  But Peter hasn't tasted alcohol in 34 years, a...   \n",
       "3                                                      \n",
       "4  Image copyright Greg Doherty / Getty Images Im...   \n",
       "\n",
       "                                         Source_URLs  \n",
       "0   https://www.bbc.co.uk/news/amp/uk-wales-45023075  \n",
       "1                https://www.bbc.co.uk/news/10280806  \n",
       "2       https://www.bbc.co.uk/news/magazine-33049093  \n",
       "3  https://www.bbc.co.uk/programmes/topics/Alcoho...  \n",
       "4  https://www.bbc.co.uk/news/amp/uk-wales-south-...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl = pd.DataFrame({'Headlines' : headlines,\n",
    "                    'Descriptions' : descriptions,\n",
    "                    'Authors' : authors,\n",
    "                    'Published_Dates' : dates, \n",
    "                    'Articles' : news,\n",
    "                    'Keywords' : keywords,\n",
    "                    'Summaries' : summaries,\n",
    "                    'Source_URLs' : urls})\n",
    "\n",
    "tbl.dropna()\n",
    "tbl.to_csv('BBC.csv', index=False)\n",
    "tbl.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
